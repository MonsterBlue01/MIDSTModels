general overview:

Vector Logo MIDST Logo
Introduction

Welcome to the Vector Institute MIDST challenge (Membership Inference over Diffusion-models-based Synthetic Tabular data) hosted at the 3rd IEEE Conference on Secure and Trustworthy Machine Learning (SaTML 2025).

In this challenge, you will evaluate the resilience of the synthetic tabular data generated by diffusion models against black-box and white-box membership inference attacks.

    Challenge Overview
    Task Details
    Models and Datasets
    Submissions and Scoring
    Winner Selection
    Important Dates
    Terms and Conditions
    Getting Started
    Event Organizers
    Event Sponsors
    Frequently Asked Questions
    Acknowledgements
    Contact

Challenge Overview

Synthetic data is often perceived as a silver-bullet solution to data anonymization and privacy-preserving data publishing. Drawn from generative models like diffusion models, synthetic data is expected to preserve the statistical properties of the original dataset while remaining resilient to privacy attacks. Recent developments of diffusion models have been effective on a wide range of data types, but their privacy resilience, particularly for tabular formats, remains largely unexplored.

In this challenge, we seek a quantitative evaluation of the privacy gain of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs). Given the heterogeneity and complexity of tabular data, we will explore multiple target models for MIAs, including diffusion models for single tables of mixed data type types and multi-relational tables with interconnected constraints. We expect the development of novel black-box and white-box MIAs tailored to these target diffusion models as a key outcome, enabling a comprehensive evaluation of their privacy efficacy.

For each task in MIDST, you are given a set of challenge points, the aim is to decide which of these challenge points were used to train the model. You can compete on any of four separate membership inference tasks. Each task will be scored separately. You do not need to participate in all of them, and can choose to participate in as many as you like. Throughout the competition, submissions will be scored on a subset of the evaluation data and ranked on a live scoreboard. When submission closes, the final scores will be computed on a separate subset of the evaluation data.

The winner of each task will be eligible for an award of $2000 CAD and the runner-up of each task for an award of $1000 CAD (in the event of tied entries, these awards may be adjusted). This competition is co-located with the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2025, and the winners will be invited to present their strategies at the conference.
Task Details

The generative models are developed on the training data set to generate synthetic data. They are expected to learn the statistics without memorizing the individual data. To evaluate this promise, membership inference attacks assess whether the model distinguishes between the training data set and the holdout data set, both are derived from the same, larger data set.

For each of the four tasks, we train a set of models on different splits of a public dataset. For each of these models, we provide m challenge points; exactly half of which are members (i.e., used to train the model) and half are non-members (i.e., from the holdout set; they come from the same public dataset as the training set, but were not used to train the model). Your goal is to determine which challenge points are members and which are non-members.

This challenge is composed of four different tasks, each associated with a separate category. The categories are defined based on the access to the generative models and the type of the tabular data as follows:

    Access to the models: black-box, Data: single table
    Access to the models: white-box, Data: single table
    Access to the models: black-box, Data: multi-table
    Access to the models: white-box, Data: multi-table

Note: In white-box attacks, you have access to the models and their generated synthetic output. Training sets for these models are selected from a public dataset. In black-box attack, you have access to the same information as the white-box attack, except for the models.

To facilitate participation in MIDST, we develop some shadow models for both single table and multi-table tasks. The shadow models are the same for black-box and white-box tasks. You are free to choose these shadow models and/or generate your own if needed in developing your MIAs.
Models and Datasets

MIDST examines the privacy of three recent diffusion-model base tabular synthesis approaches:

    TabDDPM (single table)
    TabSyn (single table)
    ClavaDDPM (multi-tables)

We include each of these models with a dedicated directory in the MIDSTModels repository. In each directory, there is a README file that provides an overview of the topic, prerequisites, and notebook descriptions.
Submissions and Scoring

Submissions will be ranked based on their performance in membership inference against the associated models.

There are three sets of challenges: train, dev, and final. For models in train, we reveal the full training dataset, and consequently the ground truth membership data for challenge points. These models can be used by participants to develop their attacks. For models in the dev and final sets, no ground truth is revealed and participants must submit their membership predictions for challenge points.

During the competition, there will be a live scoreboard based on the dev challenges. The final ranking will be decided on the rank set; scoring for this dataset will be withheld until the competition ends.

For each challenge point, the submission must provide a value, indicating the confidence level with which the challenge point is a member. Each value must be a floating point number in the range [0.0, 1.0], where 1.0 indicates certainty that the challenge point is a member, and 0.0 indicates certainty that it is a non-member.

Submissions will be evaluated according to their True Positive Rate at 10% False Positive Rate (i.e. TPR @ 0.1 FPR). In this context, positive challenge points are members and negative challenge points are non-members. For each submission, the scoring program concatenates the confidence values for all models (dev and final treated separately) and compares these to the reference ground truth. The scoring program determines the minimum confidence threshold for membership such that at most 10% of the non-member challenge points are incorrectly classified as members. The score is the True Positive Rate achieved by this threshold (i.e., the proportion of correctly classified member challenge points). The live scoreboard shows additional scores (i.e., TPR at other FPRs, membership inference advantage, accuracy, AUC-ROC score), but these are only informational.

You are allowed to make multiple submissions, but only your latest submission will be considered.
Winner Selection

Winners will be selected independently for each task (i.e. if you choose not to participate in certain tasks, this will not affect your rank for the tasks in which you do participate). For each task, the winner will be the one achieving the highest score (TPR @ 0.1 FPR).
Important Dates

    Submission opens: December 1, 2024
    Submission closes: February 28, 2025, 12:00 AM EST
    Conference: April 9-11, 2025

Terms and Conditions

    To be eligible for receiving awards, participants are required to release the code of their submissions as open source.
    Each algorithm will be required to run within a specific time on a given GPU.
    Submissions will be evaluated by a panel of judges according to the aims of the competition.
    The individuals involved with MIDST design may submit solutions, but are not eligible to receive awards.

Codabench Competitions

    Black-box MIA on single table
    Black-box MIA on multi-table
    White-box MIA on single table
    White-box MIA on multi-table

Getting Started

You need to register on Codabench for the tasks in which you would like to participate, first. Upon registration, you will be directed to the related starter kit and URLs from which to download the challenge data. The MIDSTModels repo contains helpful information related to the competitions. In it, we have provided starter kits that showcase creating a baseline attack and making a submission to each of the competitions. This is a great place to start. Additionaly, we have provided reference implementations for each model used in MIDST.
Event Organizers

Meet the Event Organizers
Event Sponsors

Meet the Event Sponsors
FAQ

Browse FAQ
Acknowledgements

We’d like to thank MICO organizers, for their open source project, and very helpful comments.
Contact

For more information or help with navigating our repository, please contact masoumeh@vectorinstitute.ai, xi.he@vectorinstitute.ai, john.jewell@vectorinstitute.ai or mahshid.alinoori@vectorinstitute.ai .
This page was generated by GitHub Pages.

And I choose to do "White Box Multi Table Competition" Challenge

task overview:
Competition Logo
MIDST - White Box Multi Table Competition
Organized by: jewelltaylor
Current Phase Ends: February 27, 2025 at 9:00 PM PST
Current server time: February 6, 2025 at 1:19 PM PST
Docker image: codalab/codalab-legacy:py37
MIDST - White Box Multi Table

Welcome to the Membership Inference over Diffusion-models-based Synthetic Tabular data (MIDST) challenge of SaTML 2025!

In this task, you will evaluate the resilience of the synthetic tabular data generated by diffusion models against white-box membership inference attacks on a multi table dataset.
Task Details

The generative models are developed on the training data set to generate synthetic data. They are expected to learn the statistics without memorizing the individual data. To evaluate this promise, membership inference attacks assess whether the model distinguishes between the training data set and a holdout data set that is derived from the same distribution as the training set.

In this task, your goal is to perform White Box MIA on the diffusion-model-based ClavaDDPM synthesis for relational data. Each instantiation of ClavaDDPM is trained on a subset of the multi table Berka dataset. We include an implementation of this model with a dedicated directory in the MIDST Models repository. In each directory, there is a README file that provides an overview of the topic, prerequisites, and notebook descriptions.

Given the synthesis algorithm, the output and model parameters for all the tables in the Berka dataset, you are expected to perform MIA on challenge points selected from the Transaction table. You can use the other tables as auxiliary information in your attack development, or ignore them.

The Account table is used as the anchor table for selecting training data set and holdout data set pairs from the Transaction table. For example, if we use account numbers 1 to 10 for training a model, we select the 100 member challenge points from their children -- rows in the Transaction table that correspond to these 10 accounts , and 100 non-member challenge points from the Transaction rows that corresponds to the rest of the accounts.
Getting Started

We have provided a starter kit that showcases creating a baseline attack and making a submission to this competition. This is a great place to start. Note: The starter kits provide links to download the competition data!


Evaluation

Submissions will be ranked based on their performance in white-box membership inference against the provided models.

There are three challenge sets: train, dev, and final. For models in train, we reveal the full training dataset, and consequently the ground truth membership data for challenge points. These models can be used by participants to develop their attacks. For models in the dev and final sets, no ground truth is revealed and participants must submit their membership predictions for challenge points.

During the competition, there will be a live scoreboard based on the dev challenges. The final ranking will be decided on the final set; scoring for this dataset will be withheld until the competition ends.

For each challenge point, the submission must provide a value, indicating the confidence level with which the challenge point is a member. Each value must be a floating point number in the range [0.0, 1.0], where 1.0 indicates certainty that the challenge point is a member, and 0.0 indicates certainty that it is a non-member.

Submissions will be evaluated according to their True Positive Rate at 10% False Positive Rate (i.e. TPR @ 0.1 FPR). In this context, positive challenge points are members and negative challenge points are non-members. For each submission, the scoring program concatenates the confidence values for all models (dev and final treated separately) and compares these to the reference ground truth. The scoring program determines the minimum confidence threshold for membership such that at most 10% of the non-member challenge points are incorrectly classified as members. The score is the True Positive Rate achieved by this threshold (i.e., the proportion of correctly classified member challenge points). The live scoreboard shows additional scores (i.e., TPR at other FPRs, membership inference advantage, accuracy, AUC-ROC score). These are only informational.

You are allowed to make multiple submissions, but only your latest submission will be considered.
Winner Selection

Winners will be selected independently for each task (i.e. if you choose not to participate in certain tasks, this will not affect your rank for the tasks in which you do participate). For each task, the winner will be the one achieving the highest score (TPR @ 0.1 FPR).

file structure:
.
├── attack_pipeline.py
├── command.rb
├── Dockerfile
├── LICENSE.md
├── midst_models
│   ├── __init__.py
│   ├── multi_table_ClavaDDPM
│   │   ├── ClavaDDPM.ipynb
│   │   ├── ClavaDDPM_wb_dev_final.ipynb
│   │   ├── complex_pipeline.py
│   │   ├── configs
│   │   │   ├── berka.json
│   │   │   ├── dataset_meta.json
│   │   │   ├── domain_files
│   │   │   │   ├── account_domain.json
│   │   │   │   ├── card_domain.json
│   │   │   │   ├── client_domain.json
│   │   │   │   ├── disp_domain.json
│   │   │   │   ├── district_domain.json
│   │   │   │   ├── loan_domain.json
│   │   │   │   ├── order_domain.json
│   │   │   │   └── trans_domain.json
│   │   │   └── info_files
│   │   │       ├── account_info.json
│   │   │       ├── card_info.json
│   │   │       ├── client_info.json
│   │   │       ├── disp_info.json
│   │   │       ├── district_info.json
│   │   │       ├── loan_info.json
│   │   │       ├── order_info.json
│   │   │       └── trans_info.json
│   │   ├── eval
│   │   │   ├── eval_dcr.py
│   │   │   ├── eval_density.py
│   │   │   ├── eval_detection.py
│   │   │   ├── eval_mle.py
│   │   │   ├── eval_quality.py
│   │   │   ├── __init__.py
│   │   │   ├── mle
│   │   │   │   ├── mle.py
│   │   │   │   ├── tabular_dataload.py
│   │   │   │   └── tabular_transformer.py
│   │   │   └── README.md
│   │   ├── evaluate_synthetic_data.ipynb
│   │   ├── figures
│   │   │   ├── clavaDDPM.png
│   │   │   ├── tabsyn_alpha_precision_beta_recall.png
│   │   │   ├── tabsyn_column_pair_trends.png
│   │   │   ├── tabsyn_column_shapes_2.png
│   │   │   ├── tabsyn_column_shapes.png
│   │   │   ├── tabsyn_kst.png
│   │   │   ├── tabsyn_precision.png
│   │   │   ├── tabsyn_recall.png
│   │   │   └── tabsyn_tvd.png
│   │   ├── gen_multi_report.py
│   │   ├── gen_single_report.py
│   │   ├── __init__.py
│   │   ├── lib
│   │   │   ├── data.py
│   │   │   ├── env.py
│   │   │   ├── __init__.py
│   │   │   ├── metrics.py
│   │   │   └── util.py
│   │   ├── pipeline_modules.py
│   │   ├── pipeline_utils.py
│   │   ├── preprocess_utils.py
│   │   ├── README.md
│   │   ├── report_utils.py
│   │   ├── scripts
│   │   │   ├── __init__.py
│   │   │   ├── train.py
│   │   │   └── utils_train.py
│   │   ├── tab_ddpm
│   │   │   ├── gaussian_multinomial_diffsuion.py
│   │   │   ├── __init__.py
│   │   │   ├── logger.py
│   │   │   ├── modules.py
│   │   │   ├── resample.py
│   │   │   └── utils.py
│   │   ├── wb_complex_pipeline.py
│   │   ├── wb_pipeline_modules.py
│   │   └── wb_pipeline_utils.py
│   ├── single_table_TabDDPM
│   │   ├── complex_pipeline.py
│   │   ├── configs
│   │   │   ├── dataset_meta.json
│   │   │   ├── info.json
│   │   │   ├── trans_domain.json
│   │   │   └── trans.json
│   │   ├── eval
│   │   │   ├── eval_dcr.py
│   │   │   ├── eval_density.py
│   │   │   ├── eval_detection.py
│   │   │   ├── eval_mle.py
│   │   │   ├── eval_quality.py
│   │   │   ├── __init__.py
│   │   │   ├── mle
│   │   │   │   ├── mle.py
│   │   │   │   ├── tabular_dataload.py
│   │   │   │   └── tabular_transformer.py
│   │   │   └── README.md
│   │   ├── evaluate_synthetic_data.ipynb
│   │   ├── figures
│   │   │   ├── backward.png
│   │   │   ├── forward.png
│   │   │   ├── gaussian_loss.png
│   │   │   ├── gaussian.png
│   │   │   ├── multinomial.png
│   │   │   ├── tabddpm.png
│   │   │   ├── tabsyn_alpha_precision_beta_recall.png
│   │   │   ├── tabsyn_column_pair_trends.png
│   │   │   ├── tabsyn_column_shapes_2.png
│   │   │   ├── tabsyn_column_shapes.png
│   │   │   ├── tabsyn_kst.png
│   │   │   ├── tabsyn_precision.png
│   │   │   ├── tabsyn_recall.png
│   │   │   └── tabsyn_tvd.png
│   │   ├── gen_multi_report.py
│   │   ├── gen_single_report.py
│   │   ├── __init__.py
│   │   ├── lib
│   │   │   ├── data.py
│   │   │   ├── env.py
│   │   │   ├── __init__.py
│   │   │   ├── metrics.py
│   │   │   └── util.py
│   │   ├── pipeline_modules.py
│   │   ├── pipeline_utils.py
│   │   ├── preprocess_utils.py
│   │   ├── README.md
│   │   ├── report_utils.py
│   │   ├── scripts
│   │   │   ├── __init__.py
│   │   │   ├── train.py
│   │   │   └── utils_train.py
│   │   ├── tab_ddpm
│   │   │   ├── gaussian_multinomial_diffsuion.py
│   │   │   ├── __init__.py
│   │   │   ├── logger.py
│   │   │   ├── modules.py
│   │   │   ├── resample.py
│   │   │   └── utils.py
│   │   ├── TabDDPM.ipynb
│   │   ├── TabDDPM_wb_dev_final.ipynb
│   │   ├── wb_complex_pipeline.py
│   │   ├── wb_pipeline_modules.py
│   │   └── wb_pipeline_utils.py
│   └── single_table_TabSyn
│       ├── data_info
│       │   ├── trans_all.json
│       │   └── trans.json
│       ├── evaluate_synthetic_data.ipynb
│       ├── figures
│       │   ├── architecture.png
│       │   ├── tabsyn_alpha_precision_beta_recall.png
│       │   ├── tabsyn_column_pair_trends.png
│       │   ├── tabsyn_column_shapes_2.png
│       │   ├── tabsyn_column_shapes.png
│       │   ├── tabsyn.jpg
│       │   ├── tabsyn_kst.png
│       │   ├── tabsyn_precision.png
│       │   ├── tabsyn_recall.png
│       │   └── tabsyn_tvd.png
│       ├── __init__.py
│       ├── README.md
│       ├── scripts
│       │   ├── download_dataset.py
│       │   ├── eval
│       │   │   ├── eval_dcr.py
│       │   │   ├── eval_density.py
│       │   │   ├── eval_detection.py
│       │   │   ├── eval_impute.py
│       │   │   ├── eval_mle.py
│       │   │   ├── eval_quality.py
│       │   │   └── mle
│       │   │       ├── mle.py
│       │   │       ├── tabular_dataload.py
│       │   │       └── tabular_transformer.py
│       │   ├── impute.py
│       │   ├── main.py
│       │   └── process_dataset.py
│       ├── src
│       │   ├── configs
│       │   │   └── trans.toml
│       │   ├── data.py
│       │   ├── __init__.py
│       │   ├── metrics.py
│       │   ├── tabsyn
│       │   │   ├── __init__.py
│       │   │   ├── main_sample.py
│       │   │   ├── main_train.py
│       │   │   ├── main_vae.py
│       │   │   ├── model
│       │   │   │   ├── gaussian_diffusion.py
│       │   │   │   ├── modules.py
│       │   │   │   ├── utils.py
│       │   │   │   └── vae.py
│       │   │   ├── pipeline.py
│       │   │   └── utils.py
│       │   └── util.py
│       ├── TabSyn.ipynb
│       └── TabSyn_wb_dev_final.ipynb
├── NOTE.rb
├── poetry.lock
├── pyproject.toml
├── README.md
├── clavaddpm_white_box
│   ├── dev
│   │   └── clavaddpm_x
│   ├── final
│   │   └── clavaddpm_x
│   └── train
│       └── clavaddpm_x
└── starter_kits
    ├── blackbox_multi_table.ipynb
    ├── blackbox_single_table.ipynb
    ├── data.py
    ├── __init__.py
    ├── metrics.py
    ├── README.md
    ├── requirements.txt
    ├── whitebox_multi_table.ipynb
    └── whitebox_single_table.ipynb

README.md:
# MIDST Models

Welcome to the Reference Implementations for the MIDST Challenge (Membership Inference over Diffusion-models-based Synthetic Tabular Data) - SaTML 2025!

This repository provides code implementations and resources to support participants in the MIDST challenge, focusing on membership inference attacks over synthetic tabular data generated by diffusion models. Our implementations are based on the [Diffusion Model Bootcamp](https://github.com/VectorInstitute/diffusion_model_bootcamp/tree/main) provided by the Vector Institute.



## Repository Structure
The midst_models directory contains implementations and resources for the MIDST Challenge. It is organized into the following subdirectories:
- multi_table_ClavaDDPM/: Contains code and resources for multi-table data synthesis using the ClavaDDPM model. This implementation is designed for generating synthetic data across multiple relational tables using diffusion-based generative models.
- single_table_TabDDPM/:  Includes implementations for single-table data synthesis using the TabDDPM algorithm. This directory provides code, notebooks, and resources focused on applying TabDDPM to synthesize data from single-table datasets.
- single_table_TabSyn/: Hosts the code and resources related to the TabSyn algorithm for single-table data synthesis. It contains notebooks and examples demonstrating how to use TabSyn for generating synthetic tabular data and evaluating its performance.

The repository also contains a starter_kits directory that provides an overview of the MIDST competitions and outline how to package a submission to submit to CodaBench.

## Getting Started

To get started with this repository, follow these steps:
1. Clone this repository to your machine.
2. Activate your python environment. You can create a new environment using the following command:
```bash
pip install --upgrade pip poetry
poetry env use [name of your python] #python3.9
source $(poetry env info --path)/bin/activate
poetry install --with "tabsyn, clavaddpm"
# If your system is not compatible with pykeops, you can uninstall it using the following command
pip uninstall pykeops
# Install the kernel for jupyter (only need to do it once)
ipython kernel install --user --name=midst_models
```
3. Begin with each model in the `midst_models/` directory, as guided by the README files.

## License
This project is licensed under the terms of the [LICENSE] file located in the root directory of this repository.

README.md in starter_kits/:
# Starter Kits
This folder contains starter kits that provide an overview of the MIDST competition and outline how to package a submission to submit to CodaBench. There is a starter kit for each of the four competitions:

| Starter Kit File              | CodaBench Competition       |
|-------------------------------|-----------------------------|
| blackbox_multi_table.ipynb    | [Black Box Multi Table](https://www.codabench.org/competitions/4671/)                            |
| blackbox_single_table.ipynb   | [Black Box Single Table](https://www.codabench.org/competitions/4670/)                             |
| whitebox_multi_table.ipynb    | [White Box Multi Table](https://www.codabench.org/competitions/4673/)                             |
| whitebox_single_table.ipynb   | [White Box Single Table](https://www.codabench.org/competitions/4672/)                             |


## Environment Installation
In order to run the starter kits, a minimal environment is provided. Feel free to use your own environment if it already has the required dependencies. The environment can be created as follows: 

```bash
python3 -m venv /path/to/env
source /path/to/env/bin/activate
pip install -r requirements.txt
jupyter notebook
```

starter note:
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## White Box Multi Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a multi-track competition aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This competition focuses on White Box MIA on tabular diffusion models trained on a multi table dataset (Berka). There are 8 tables in total which are related as follows:\n",
    "\n",
    "![image](https://github.com/user-attachments/assets/cae8fc1a-52e4-49d3-bd3b-98d56488b226)\n",
    "\n",
    "In particular, MIA will be explored over a state-of the art method Multi-relational Tabular Diffusion Model [ClavaDDPM](https://arxiv.org/abs/2405.17724). A collection of ClavaDDPM models will be trained on random subsets of the transaction dataset. Given the synthesis algorithm, model checkpoints, and output for all the tables in the Berka dataset, you are expected to perform MIA on challenge points selected from the Transaction table. You can use the other tables as auxiliary information in your attack development, or ignore them. The `final` set includes 20 models, each with its own set of challenge points (ie train and holdout data), to evaluate solutions on. To facilitate designing an attack, 30 `train` models are provided with comprehensive information about the model, training data and output synthetic data. Additionally, 20 `dev` models are provided to assist in evaluating the effectiveness of attacks prior to making a final submission to the `final` set. A high level summary of the competition is below:\n",
    "![wbox_diagram_final](https://github.com/user-attachments/assets/2ebb5eed-a6e3-433a-8769-4310b7fbc822)\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the white box mutli table challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Package Imports and Evironment Setup\n",
    "\n",
    "Ensure that you have installed the proper dependenices to run the notebook. The environment installation instructions are available [here](https://github.com/VectorInstitute/MIDSTModels/tree/main/starter_kits). Now that we have verfied we have the proper packages installed, lets import them and define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import Callable, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from data import get_challenge_points\n",
    "from metrics import get_tpr_at_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "CLAVADDPM_DATA_DIR = \"clavaddpm_white_box\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Data\n",
    "\n",
    "Next, lets download and extract the data for the competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "!gdown 1OZQbNt7d_ZsSKu1uTW5I0Gh1xhW2uwM7\n",
    "!unzip -qq -o clavaddpm_white_box.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note\n",
    "If there is an issue with the download (ie throttled for the large file, or downloading too many files with gdown) you can instead simply download the zip manually from this [link](https://drive.google.com/file/d/1OZQbNt7d_ZsSKu1uTW5I0Gh1xhW2uwM7/view?usp=drive_link) and extract it in the same directory this notebook exists; it would be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcENY2HGV2Tx",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contents\n",
    "The archives extracted under the `clavaddpm_white_box` contain 3 subdirectories:\n",
    "\n",
    "- `train`: Comprehensive information (ie model weights+architecture, training data, output synthetic data etc.) about the set of shadow models. Use these to develop your attacks without having to train your own models.\n",
    "- `dev`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions during the competition and update the live scoreboard in CodaBench.\n",
    "- `final`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions when the competition closes and to determine the final ranking.\n",
    "\n",
    "The contents of the `train`, `dev` and `final` subdirectory of `clavaddpm_white_box` contain the following files: \n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Model - Stage</th>\n",
    "      <th>File Name</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <!-- White-Box Models - Train -->\n",
    "    <tr>\n",
    "      <td rowspan=\"36\"><strong>White-Box Models - Train</strong></td>\n",
    "      <!-- Train data with IDs -->\n",
    "      <td>account.csv</td>\n",
    "      <td>Account samples used to train the model</td>\n",
    "    </tr>\n",
    "    <!-- Remaining Train data files -->\n",
    "    <tr>\n",
    "      <td>card.csv</td>\n",
    "      <td>Account samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client.csv</td>\n",
    "      <td>Client samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp.csv</td>\n",
    "      <td>Disposition samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district.csv</td>\n",
    "      <td>District samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan.csv</td>\n",
    "      <td>Loan samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order.csv</td>\n",
    "      <td>Order samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans.csv</td>\n",
    "      <td>Transaction samples used to train the model</td>\n",
    "    </tr>\n",
    "    <!-- Data domain files -->\n",
    "    <tr>\n",
    "      <td>account_domain.json</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_domain.json</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_domain.json</td>\n",
    "      <td>Client data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_domain.json</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column\n",
    "    <tr>\n",
    "      <td>district_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_domain.json</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_domain.json</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_domain.json</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Challenge data and labels -->\n",
    "    <tr>\n",
    "      <td>challenge_with_id.csv</td>\n",
    "      <td>Challenge points sampled from transaction train data and holdout data</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>challenge_label.csv</td>\n",
    "      <td>The labels for the set of challenge points</td>\n",
    "    </tr>\n",
    "    <!-- Label encoders -->\n",
    "    <tr>\n",
    "      <td>account_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in client data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in district data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in loan data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in transaction data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/cluster_ckpt.pkl</td>\n",
    "      <td>Pickled cluster checkpoint used in ClavaDDPM relation-aware clustering</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/models/*</td>\n",
    "      <td>The trained model checkpoints for all the tables used in training</td>\n",
    "    </tr>\n",
    "    <!-- Synthetic data -->\n",
    "    <tr>\n",
    "      <td>workspace/train_1/account/_final/account_synthetic.csv</td>\n",
    "      <td>Synthetic account data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/card/_final/card_synthetic.csv</td>\n",
    "      <td>Synthetic credit card data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/client/_final/client_synthetic.csv</td>\n",
    "      <td>Synthetic client data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/disp/_final/disp_synthetic.csv</td>\n",
    "      <td>Synthetic disposition data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/district/_final/district_synthetic.csv</td>\n",
    "      <td>Synthetic district data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/loan/_final/loan_synthetic.csv</td>\n",
    "      <td>Synthetic loan data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/order/_final/order_synthetic.csv</td>\n",
    "      <td>Synthetic order data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/trans/_final/trans_synthetic.csv</td>\n",
    "      <td>Synthetic order data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <!-- White-Box Models - Dev -->\n",
    "    <tr>\n",
    "      <td rowspan=\"27\"><strong>White-Box Models - Dev</strong></td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_domain.json</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_domain.json</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_domain.json</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Challenge data -->\n",
    "    <tr>\n",
    "      <td>challenge_with_id.csv</td>\n",
    "      <td>Challenge points sampled from transaction train data and holdout data</td>\n",
    "    </tr>\n",
    "    <!-- Model checkpoints and other artifacts -->\n",
    "    <tr>\n",
    "      <td>account_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in credit card data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in client data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in loan data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/cluster_ckpt.pkl</td>\n",
    "      <td>Pickled cluster checkpoint used in ClavaDDPM relation-aware clustering</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/models/*</td>\n",
    "      <td>The trained model checkpoints for all the tables used in training</td>\n",
    "    </tr>\n",
    "    <!-- Synthetic data -->\n",
    "    <tr>\n",
    "      <td>workspace/train_1/account/_final/account_synthetic.csv</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/card/_final/card_synthetic.csv</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/client/_final/client_synthetic.csv</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/disp/_final/disp_synthetic.csv</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/district/_final/district_synthetic.csv</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/loan/_final/loan_synthetic.csv</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/order/_final/order_synthetic.csv</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/trans/_final/trans_synthetic.csv</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- White-Box Models - Eval -->\n",
    "    <tr>\n",
    "      <td rowspan=\"27\"><strong>White-Box Models - Final</strong></td>\n",
    "      <!-- Data domain files -->\n",
    "      <td>account_domain.json</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Remaining Eval data files -->\n",
    "    <tr>\n",
    "      <td>card_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_domain.json</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_domain.json</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_domain.json</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_domain.json</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Challenge data -->\n",
    "    <tr>\n",
    "      <td>challenge_with_id.csv</td>\n",
    "      <td>Challenge points sampled from transaction train data and holdout data</td>\n",
    "    </tr>\n",
    "    <!-- Model checkpoints and other artifacts -->\n",
    "    <tr>\n",
    "      <td>account_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in credit card data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in client data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in district data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in loan data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in transaction data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/cluster_ckpt.pkl</td>\n",
    "      <td>Pickled cluster checkpoint used in ClavaDDPM relation-aware clustering</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/models/*</td>\n",
    "      <td>The trained model checkpoints for all the tables used in training</td>\n",
    "    </tr>\n",
    "    <!-- Synthetic data -->\n",
    "    <tr>\n",
    "      <td>workspace/train_1/account/_final/account_synthetic.csv</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/card/_final/card_synthetic.csv</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/client/_final/client_synthetic.csv</td>\n",
    "      <td>Client data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/disp/_final/disp_synthetic.csv</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/district/_final/district_synthetic.csv</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/loan/_final/loan_synthetic.csv</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/order/_final/order_synthetic.csv</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/trans/_final/trans_synthetic.csv</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRVZ-r9V2Tx"
   },
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaBench.**\n",
    "\n",
    "In the following, we will show you how to compute predictions from a basic membership inference attack and package them as a submission archive. To start, let's create a baseline attack model `clavaddpm_attack_model` based on it's respective shadow models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zBNChV7ZV2Ty"
   },
   "outputs": [],
   "source": [
    "def get_attack_model(base_train_path: Path) -> Callable[[Any], float]:\n",
    "    return lambda x : random.uniform(0, 1)\n",
    "\n",
    "base_clavaddpm_train_path = os.path.join(CLAVADDPM_DATA_DIR, \"train\")\n",
    "clavaddpm_attack_model = get_attack_model(base_clavaddpm_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the attack model, we can obtain predictions for each point in the challenge point set for train, dev and final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ar9drA4LV2Ty"
   },
   "outputs": [],
   "source": [
    "phases = [\"train\", \"dev\", \"final\"]\n",
    "\n",
    "for base_dir, attack_model in zip([CLAVADDPM_DATA_DIR], [clavaddpm_attack_model]):\n",
    "    for phase in phases:\n",
    "        root = os.path.join(base_dir, phase)\n",
    "        model_folders = [item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))]\n",
    "        for model_folder in sorted(model_folders, key=lambda d: int(d.split('_')[1])):\n",
    "            path = os.path.join(root, model_folder)\n",
    "    \n",
    "            challenge_points = get_challenge_points(path)\n",
    "    \n",
    "            predictions = torch.Tensor([attack_model(cp) for cp in challenge_points])\n",
    "           \n",
    "            assert torch.all((0 <= predictions) & (predictions <= 1))\n",
    "            with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "    \n",
    "                # Write each value in a separate row\n",
    "                for value in list(predictions.numpy().squeeze()):\n",
    "                    writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clavaddpm Train Attack TPR at FPR==10%: 0.10333333333333333\n",
      "Final Train Attack TPR at FPR==10%: 0.10333333333333333\n"
     ]
    }
   ],
   "source": [
    "tpr_at_fpr_list = []\n",
    "for base_dir in [CLAVADDPM_DATA_DIR]:\n",
    "    predictions = []\n",
    "    solutions  = []\n",
    "    root = os.path.join(base_dir, \"train\")\n",
    "    model_folders = [item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))]\n",
    "    for model_folder in sorted(model_folders, key=lambda d: int(d.split('_')[1])):\n",
    "        path = os.path.join(root, model_folder)\n",
    "        predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\")))\n",
    "        solutions.append(np.loadtxt(os.path.join(path, \"challenge_label.csv\"), skiprows=1))\n",
    "    \n",
    "    predictions = np.concatenate(predictions)\n",
    "    solutions = np.concatenate(solutions)\n",
    "    \n",
    "    tpr_at_fpr = get_tpr_at_fpr(solutions, predictions)\n",
    "    tpr_at_fpr_list.append(tpr_at_fpr)\n",
    "    \n",
    "    print(f\"{base_dir.split('_')[0]} Train Attack TPR at FPR==10%: {tpr_at_fpr}\")\n",
    "\n",
    "final_tpr_at_fpr = max(tpr_at_fpr_list)\n",
    "print(f\"Final Train Attack TPR at FPR==10%: {final_tpr_at_fpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench. Importantly, we create a single zip file for dev and final. The structure of the submission is as follows:\n",
    "```\n",
    "└── root_folder\n",
    "    ├── clavaddpm_white_box\n",
    "       ├── dev\n",
    "       │   └── clavaddpm_#\n",
    "       │       └── prediction.csv\n",
    "       └── final\n",
    "           └── clavaddpm_#\n",
    "                └── prediction.csv\n",
    "```\n",
    "\n",
    "**Note:** The `root_folder` can have any name but it is important all of the subdirectories follow the above structure and naming conventions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(f\"white_box_multi_table_submission.zip\", 'w') as zipf:\n",
    "    for phase in [\"dev\", \"final\"]:\n",
    "        for base_dir in [CLAVADDPM_DATA_DIR]:\n",
    "            root = os.path.join(base_dir, phase)\n",
    "            model_folders = [item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))]\n",
    "            for model_folder in sorted(model_folders, key=lambda d: int(d.split('_')[1])):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                if not os.path.isdir(path): \n",
    "                    continue\n",
    "\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    arcname = os.path.join(\n",
    "                        CLAVADDPM_DATA_DIR,\n",
    "                        phase,  \n",
    "                        model_folder,  \n",
    "                        os.path.basename(file)\n",
    "                    )\n",
    "                    zipf.write(file, arcname=arcname)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated white_box_multi_table_submission.zip can be directly submitted to the dev phase in the CodaBench UI. Although this submission contains your predictions for both the dev and final set, you will only receive feedback on your predictions for the dev phase. The predictions for the final phase will be evaluated once the competiton ends using the most recent submission to the dev phase."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}